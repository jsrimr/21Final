{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M2177.003100 Deep Learning <br> Final Project: Text-to-Image Synthesis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (C) Data Science & AI Laboratory, Seoul National University. This material is for educational uses only. Some contents are based on the material provided by other paper/book authors and may be copyrighted by them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For understanding of this work, please carefully look at given PDF file.**\n",
    "\n",
    "**Note**: certain details are missing or ambiguous on purpose, in order to test your knowledge on the related materials. However, if you really feel that something essential is missing and cannot proceed to the next step, then contact the teaching staff with clear description of your problem.\n",
    "\n",
    "### Submitting your work:\n",
    "<font color=red>**DO NOT clear the training process **</font> so that TAs can grade both your code and results.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os, nltk\n",
    "import numpy as np\n",
    "\n",
    "from miscc.config import cfg, cfg_from_file\n",
    "import pprint\n",
    "import datetime\n",
    "import dateutil.tz\n",
    "\n",
    "from utils.data_utils import CUBDataset\n",
    "from utils.trainer import trainer\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using config:\n",
      "{'BATCH_SIZE': 64,\n",
      " 'CHECKPOINT_DIR': './checkpoint',\n",
      " 'CHECKPOINT_NAME': '',\n",
      " 'CNN': {'EMBEDDING_DIM': 0, 'H_DIM': 0},\n",
      " 'CONFIG_NAME': 'text-to-image',\n",
      " 'CUDA': True,\n",
      " 'DATASET_NAME': 'birds',\n",
      " 'DATA_DIR': 'data/birds',\n",
      " 'EMBEDDING_TYPE': 'cnn-rnn',\n",
      " 'GAN': {'B_ATTENTION': False,\n",
      "         'B_CONDITION': False,\n",
      "         'B_DCGAN': False,\n",
      "         'CONDITION_DIM': 100,\n",
      "         'DF_DIM': 32,\n",
      "         'EMBEDDING_DIM': 0,\n",
      "         'GF_DIM': 64,\n",
      "         'R_NUM': 2,\n",
      "         'Z_DIM': 100},\n",
      " 'GPU_ID': '0',\n",
      " 'IMAGE_SIZE': 128,\n",
      " 'NUM_BATCH_FOR_TEST': 0,\n",
      " 'RANDOM_SEED': 0,\n",
      " 'RNN': {'EMBEDDING_DIM': 0,\n",
      "         'H_DIM': 0,\n",
      "         'TYPE': 'LSTM',\n",
      "         'VOCAB_SIZE': 0,\n",
      "         'WORD_EMBEDDING_DIM': 0},\n",
      " 'R_PRECISION_DIR': '',\n",
      " 'R_PRECISION_FILE': '',\n",
      " 'R_PRECISION_FILE_HIDDEN': '',\n",
      " 'TEST': {'B_EXAMPLE': False,\n",
      "          'GENERATED_HIDDEN_TEST_IMAGES': '',\n",
      "          'GENERATED_TEST_IMAGES': './evaluation/generated_images'},\n",
      " 'TEXT': {'CAPTIONS_PER_IMAGE': 10, 'EMBEDDING_DIM': 256, 'WORDS_NUM': 18},\n",
      " 'TRAIN': {'B_NET_D': False,\n",
      "           'CNN_ENCODER': '',\n",
      "           'COEFF': {'COLOR_LOSS': 0.0, 'KL': 0.0, 'UNCOND_LOSS': 0.0},\n",
      "           'DISCRIMINATOR': '',\n",
      "           'DISCRIMINATOR_LR': 0.0002,\n",
      "           'FLAG': True,\n",
      "           'GENERATOR': '',\n",
      "           'GENERATOR_LR': 0.0002,\n",
      "           'MAX_EPOCH': 600,\n",
      "           'RNN_ENCODER': '',\n",
      "           'SMOOTH': {'GAMMA1': 0.0,\n",
      "                      'GAMMA2': 0.0,\n",
      "                      'GAMMA3': 0.0,\n",
      "                      'LAMBDA': 0.0},\n",
      "           'SNAPSHOT_INTERVAL': 50},\n",
      " 'TREE': {'BASE_SIZE': 32, 'BRANCH_NUM': 2},\n",
      " 'WORKERS': 4,\n",
      " 'WRONG_CAPTION': 9}\n"
     ]
    }
   ],
   "source": [
    "# Set a config file as 'train_birds.yml' in training, as 'eval_birds.yml' for evaluation\n",
    "cfg_from_file('cfg/train_birds.yml') # eval_birds.yml\n",
    "\n",
    "print('Using config:')\n",
    "pprint.pprint(cfg)\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = cfg.GPU_ID\n",
    "\n",
    "now = datetime.datetime.now(dateutil.tz.tzlocal())\n",
    "timestamp = now.strftime('%Y_%m_%d_%H_%M_%S')\n",
    "output_dir = 'sample/%s_%s_%s' % (cfg.DATASET_NAME, cfg.CONFIG_NAME, timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.current_dir:\n",
      "/home/gpuadmin/21Final\n",
      "\n",
      "self.data_dir:\n",
      "/home/gpuadmin/21Final/data/birds\n",
      "\n",
      "self.image_dir:\n",
      "/home/gpuadmin/21Final/data/birds/CUB-200-2011/images\n",
      "\n",
      "filepath /home/gpuadmin/21Final/data/birds/captions.pickle\n",
      "Load from:  /home/gpuadmin/21Final/data/birds/captions.pickle\n",
      "self.current_dir:\n",
      "/home/gpuadmin/21Final\n",
      "\n",
      "self.data_dir:\n",
      "/home/gpuadmin/21Final/data/birds\n",
      "\n",
      "self.image_dir:\n",
      "/home/gpuadmin/21Final/data/birds/CUB-200-2011/images\n",
      "\n",
      "filepath /home/gpuadmin/21Final/data/birds/captions.pickle\n",
      "Load from:  /home/gpuadmin/21Final/data/birds/captions.pickle\n",
      "train data directory:\n",
      "/home/gpuadmin/21Final/data/birds/train\n",
      "test data directory:\n",
      "/home/gpuadmin/21Final/data/birds/test\n",
      "\n",
      "# of train filenames:(8855,)\n",
      "# of test filenames:(2933,)\n",
      "\n",
      "example of filename of train image:002.Laysan_Albatross/Laysan_Albatross_0002_1027\n",
      "example of filename of valid image:001.Black_footed_Albatross/Black_Footed_Albatross_0046_18\n",
      "\n",
      "example of caption and its ids:\n",
      "['a', 'bird', 'with', 'a', 'very', 'long', 'wing', 'span', 'and', 'a', 'long', 'pointed', 'beak']\n",
      "[1, 2, 3, 1, 4, 5, 6, 7, 8, 1, 5, 9, 10]\n",
      "\n",
      "example of caption and its ids:\n",
      "['this', 'is', 'a', 'small', 'bird', 'that', 'has', 'a', 'brilliant', 'blue', 'color', 'on', 'it', 's', 'body', 'a', 'slightly', 'darker', 'blue', 'on', 'it', 's', 'head', 'a', 'teal', 'color', 'on', 'it', 's', 'wings', 'and', 'a', 'light', 'colored', 'beak']\n",
      "[18, 19, 1, 250, 2, 33, 13, 1, 853, 50, 37, 86, 53, 54, 15, 1, 178, 31, 50, 86, 53, 54, 25, 1, 1054, 37, 86, 53, 54, 17, 8, 1, 67, 89, 10]\n",
      "\n",
      "# of train captions:(88550,)\n",
      "# of test captions:(29330,)\n",
      "\n",
      "# of train caption ids:(88550,)\n",
      "# of test caption ids:(29330,)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26622/1109519776.py:22: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  print(f'# of train captions:{np.asarray(train_dataset.captions).shape}')\n",
      "/tmp/ipykernel_26622/1109519776.py:23: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  print(f'# of test captions:{np.asarray(test_dataset.captions).shape}\\n')\n",
      "/tmp/ipykernel_26622/1109519776.py:25: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  print(f'# of train caption ids:{np.asarray(train_dataset.captions_ids).shape}')\n",
      "/tmp/ipykernel_26622/1109519776.py:26: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  print(f'# of test caption ids:{np.asarray(test_dataset.captions_ids).shape}\\n')\n"
     ]
    }
   ],
   "source": [
    "imsize = cfg.TREE.BASE_SIZE * (4 ** (cfg.TREE.BRANCH_NUM - 1))\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize(int(imsize)),\n",
    "    transforms.RandomCrop(imsize),\n",
    "    transforms.RandomHorizontalFlip()])\n",
    "\n",
    "train_dataset = CUBDataset(cfg.DATA_DIR, transform=image_transform, split='train')\n",
    "test_dataset = CUBDataset(cfg.DATA_DIR, transform=image_transform, split='test')\n",
    "\n",
    "print(f'train data directory:\\n{train_dataset.split_dir}')\n",
    "print(f'test data directory:\\n{test_dataset.split_dir}\\n')\n",
    "\n",
    "print(f'# of train filenames:{train_dataset.filenames.shape}')\n",
    "print(f'# of test filenames:{test_dataset.filenames.shape}\\n')\n",
    "\n",
    "print(f'example of filename of train image:{train_dataset.filenames[0]}')\n",
    "print(f'example of filename of valid image:{test_dataset.filenames[0]}\\n')\n",
    "\n",
    "print(f'example of caption and its ids:\\n{train_dataset.captions[0]}\\n{train_dataset.captions_ids[0]}\\n')\n",
    "print(f'example of caption and its ids:\\n{test_dataset.captions[0]}\\n{test_dataset.captions_ids[0]}\\n')\n",
    "\n",
    "print(f'# of train captions:{np.asarray(train_dataset.captions).shape}')\n",
    "print(f'# of test captions:{np.asarray(test_dataset.captions).shape}\\n')\n",
    "\n",
    "print(f'# of train caption ids:{np.asarray(train_dataset.captions_ids).shape}')\n",
    "print(f'# of test caption ids:{np.asarray(test_dataset.captions_ids).shape}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=cfg.BATCH_SIZE,\n",
    "        drop_last=True, shuffle=True, num_workers=int(cfg.WORKERS))\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=cfg.BATCH_SIZE,\n",
    "        drop_last=True, shuffle=False, num_workers=int(cfg.WORKERS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define models and go to train/evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = trainer(output_dir, train_dataset, train_dataloader, test_dataset, test_dataloader)\n",
    "\n",
    "if cfg.TRAIN.FLAG:\n",
    "    algo.train()\n",
    "else:\n",
    "    algo.generate_eval_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Measure Inception score and R-precision of given test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After set the config file as 'eval_birds.yml' and run the 'algo.generate_eval_data()', the synthesized images based on given captions and set of image and caption features should be saved inside a 'evaluation' folder, specifically in 'evaluation/generated_images/..'.\n",
    "\n",
    "**Then, go to the 'evaluation' folder and run each 'inception_score.ipynb' and 'r_precision.ipynb' file in order to measure inception score and r-precision score.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "21f13c09be9aa322f043e098aa9693fc93fdc025a59fa8fc9bca446dc1c24bb6"
  },
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
